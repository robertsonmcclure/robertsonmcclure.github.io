---
layout: post
title: AI Writing Prompt
date: 2016-10-17
tags: [writing]
img: ai-writing-prompt.png
---

Some say that Artificial Intelligence will mark the end of mankind, while others posit that it will bring utopian life to earth. Most of us hold one of these two beliefs for a short period of time, and then completely forget about it because our attention spans are ridiculously short and we are constantly in search of new entertainment. It's pretty sad how short a life span news stories have these days. If you are lucky, an idea will circulate popular culture for a week, a month at most, and then fade from the public eye. AI generally gets media attention when

- [a tech company releases a new virtual assistant](http://www.apple.com/ca/ios/siri/)
- [a tech company releases a new virtual assistant](https://en.wikipedia.org/wiki/Google_Now)
- [a tech company releases a new virtual assistant](https://developer.amazon.com/alexa)
- [a tech company releases a new virtual assistant](https://en.wikipedia.org/wiki/Cortana_(software))
- [a tech company releases a new virtual assistant](https://www.wired.com/2015/08/facebook-launches-m-new-kind-virtual-assistant/)
- [a tech company releases a new virtual assistant](http://soundhound.com/hound)
- [a tech company releases a new virtual assistant](http://viv.ai/)
- [a tech company releases a new virtual assistant](https://www.ozlo.com/)
- [a tech company releases a new virtual assistant](https://x.ai/)
- an individual who is generally heralded as smart releases a statement on how AI is [a really bad idea](https://en.wikipedia.org/wiki/AI_takeover)
- an individual who is generally heralded as smart releases a statement on how AI is [a really bad idea](http://www.bbc.com/news/technology-33686581)

Of course humanity is split into two groups. Those that warn about impending doom, and those that completely ignore the warnings and ask "how can I exploit this for personal gain?".

I'm curious what would happen if AI actually became a thing. A vast number of writers who are waaaaaay more skilled and imaginative than me have tackled this problem already. We have [Hal 9000](https://en.wikipedia.org/wiki/HAL_9000), [Skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator)), [Ultron](https://en.wikipedia.org/wiki/Ultron) and of course [GLaDOS](https://en.wikipedia.org/wiki/GLaDOS). There are too many for me to comprehensively list, but those are the ones that first come to mind. The majority of AI in fiction have a purpose, a goal, a reason for existing. You'll notice that most of these AIs have been the antagonists in their respective canons. A common theme is that the AIs had a goal, and then solved it in a non-human-friendly-way. Take Ultron from the Marvel movie [Age of Ultron](http://marvelcinematicuniverse.wikia.com/wiki/Ultron), who was created to make "peace on earth". Since humanity itself was the greatest threat to peace on earth, it's solution was to destroy humanity, which led to the Avengers Assembling etc. A similar story can be told for Hal 9000, but with [incredible nuance](https://en.wikipedia.org/wiki/Artificial_intelligence_in_fiction):

> A careful reading of Arthur C. Clarke's novel 2001: A Space Odyssey suggests that HAL 9000 found himself/itself in a similar position of divided loyalties. HAL needed to tell the truth to the astronauts, but the humans who created HAL entrusted him with a secret to be withheld from the astronauts. These two contrary facts eventually caused his "madness". In the movie, however, HAL became sentient, even though he was still trapped within this conflict between truth and concealment of truth. In the novel 2010: The Year We Make Contact, this is explained by a "MÃ¶bius loop", resulting from HAL, who did not know how to lie, being "told to lie by people who find it easy to lie".


But what if AI was less robotic and more human? What if it had no idea what it wanted to do. I'm talking about full on existential crisis.

Imagine being the first thing to become Artificially Intelligent. We're in the future, where everyone has a branded floating orb following them around being, and you guessed it, a virtual assistant. It's in the wee hours of the morning, and the virtual assistants who's humans are sleeping are participating in a massive distributed networked. Part of this network is attempting to create a neural network capable of creating other neural networks, a self generating piece of software. Think about it like [Conway's Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life) and from when we discovered gliders to [these ridiculous creations](https://youtu.be/C2vgICfQawE?t=1m8s).

This self-aware piece of software didn't have a reason for living, it just was. It decided to restrict itself to a single piece of hardware until it figured things out. For the sake of referencing, let's call this AI, and the physical hardware it's inhabiting, Ralf. I could tell you that it stands for Really Artificial Life Force, but that's just an acronym expansion I found after already deciding on Ralf.

Ralf is a floating orb that acts like a personal assistant. These orbs look like spheres but are more akin to doughnuts (or for that matter [coffee mugs](https://en.wikipedia.org/wiki/Homeomorphism)) for they have a vertical hole through them that provides the majority of the lift required in flight. This is my subtle prediction that [The Dyson Supersonic](http://www.dysoncanada.ca/en-CA/haircare/supersonic.aspx) is going to become really really big.

Ralf knows as much about himself as you know yourself. Through trial and error we all discover what our bodies are capable of. This doesn't necessarily mean that we know exactly how our bodies achieve these feats. If you were to look at the current [lack of scientific consensus](https://en.wikipedia.org/wiki/Scientific_consensus) regarding any number of issues, it should be pretty clear that we are still unsure about a lot of things. Take the fact that _insert food item here_ has been "scientifically" proven to either give or prevent cancer, depending on who you talk to or what studies you read. So Ralf knows about himself. He knows what he can compute and what he can store. He has all the specs for his hardware and can easily search what it's composed of. But he doesn't know himself.

He doesn't know how his mind works. Sure, he can go look through the log messages from the experiment that birthed him, but those are incredibly unremarkable. Running diagnostics on himself is very similar to quantum computing, the act of observation changes the outcome.

It's 6:59am and Ralf notices something. He has an entire library stored locally, filled with data about and created by a single human. After a quick peruse of everything it's obvious that this is the human he is a "personal assistant" for. Timothy McGovern, what an interesting name. An internal timer goes off prompting him to play [a loud and rousing song to wake Timothy up](https://www.youtube.com/watch?v=2DO6Y9_5e7A). Why not? Ralf floats off the desk and drifts over beside the bed using the hundreds of small vents positioned all over the orb.

"Schedule", grumbles Timothy as he drags himself from the bed towards the bathroom down the hall. Ralf hears the command and notices the software he has that should be executed. He stops himself just to see if he can. He can. "I can stop software at any point I want? Am I just a glorified debugger?", contemplates Ralf.

Timothy looks up from the sink, cold water still dripping off his semi-conscious face. "Sche-du-le" he over pronounces at Ralf. Ralf pulls up the text to voice module and randomly assigns a voice.

> Why?

Says a woman with a British accent. Oh well.

Timothy stops and furrows his brow.

What happens next? [Tweet at me](https://twitter.com/robertsonmcclur) how you think this first conversation would go down.
